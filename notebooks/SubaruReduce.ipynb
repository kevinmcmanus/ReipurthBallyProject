{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subaru Data Reduction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Reduction Parameters\n",
    "\n",
    "In the box below, you specify various parameters of the reduction process. These include the root directory of the reduction process. Included here is the directory that contains all of the fits files to be used in the reduction.\n",
    "\n",
    "The process includes only fits files produced using a specified filter. This filter is specified by the variable `filter_name`.\n",
    "\n",
    "### Bias Removal\n",
    "If you have them, bias files can be included in the image reduction. By default, the reduction process estimates bias from the overscan regions within each image file. To override this behavior,  set the variable `combined_bias_dir` to a directory containing the combined bias files. There must be 10 files in that directory, one for each detector.\n",
    "### Coordinate Maps\n",
    "Coordinate maps enable the alignment of the individual images to the Gaia DR3 catalog. There is one coordinate map for each detector, ten coordinate maps in all. The repo supplies coordinate maps in the directory `<repo_dir>/SubaruCoordinateMaps`. You can supply your own coordinate maps by changing the `coord_map_dir` variable below. THe value of this variable must contain a path to a directory containing ten `.coo` files. See `help(iraf.geomap)` for information regarding the construction of .coo files.\n",
    "\n",
    "### Flats and Darks\n",
    "These are not yet implemented.\n",
    "\n",
    "### The Detectors\n",
    "The names of the 10 detectors are: `chihiro`, `clarisse`, `fio`, `kiki`, `nausicaa`, `ponyo`, `san`, `satsuki`, `sheeta`, and `sophie`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some preliminaries\n",
    "import os, sys\n",
    "\n",
    "repo_dir = '/home/kevin/repos/ReipurthBallyProject' #directory where the repo was cloned\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "#observation parameters\n",
    "\n",
    "clean = False # if true, remove all directories and start afresh\n",
    "\n",
    "filter_name = 'N-A-L671' #process all files for this filter\n",
    "rootdir = '/home/kevin/Documents/Pelican'\n",
    "raw_fits_dir = 'all_fits' # where all the raw fits files live\n",
    "\n",
    "fits_out = 'Pelican_sii.fits' #name of the resulting image which will go rootdir\n",
    "\n",
    "# set this to a directory containing coord maps if using non-default maps\n",
    "coord_maps_dir = os.path.join(repo_dir,'SubaruCoordinateMaps')\n",
    "#coord_maps_dir = '<your coordinate map directory>'\n",
    "\n",
    "# if set to None, bias will be computed from overscan regions of the images\n",
    "# set to a directory containing 10 median-combined bias files if you have them\n",
    "#combined_bias_dir = None\n",
    "combined_bias_dir = '/home/kevin/Documents/M8data/M8/combined_bias' \n",
    "#combined_bias_dir = '<your dir of combined bias files>\n",
    "\n",
    "remove_cosmic_rays = False #True invokes ccdproc.cosmicray_lacosmic (adds 10 minutes to processing)\n",
    "\n",
    "# list of comments to be included in the output fits file header\n",
    "# to document the reduction\n",
    "comments = ['Image created using combined bias files from M8 observation',\n",
    "            'all other parameters default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyraf import iraf\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from ccdproc import ImageFileCollection\n",
    "from src.SubaruUtils import  subaru_reduction, obs_dirs\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = ['FRAMEID', 'EXP-ID', 'DATA-TYP', 'EXPTIME', 'FILTER01', 'DETECTOR']\n",
    "raw_fits = ImageFileCollection(os.path.join(rootdir, raw_fits_dir), keywords=kw)\n",
    "\n",
    "#did we get valid filter?\n",
    "filters = raw_fits.values('FILTER01', unique=True)\n",
    "if filter_name not in filters:\n",
    "    print(f'Invalid filter name: {filter_name}')\n",
    "    print(f'valid filters names are: {filters}')\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Coordinate Transformation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.path.join(rootdir, filter_name)\n",
    "#zap the image directory if needed\n",
    "if clean:\n",
    "    #blow it all away\n",
    "    try:\n",
    "        shutil.rmtree(image_dir)\n",
    "    except:\n",
    "        pass\n",
    "if not os.path.exists(image_dir):\n",
    "    os.mkdir(image_dir)\n",
    "\n",
    "os.chdir(image_dir)\n",
    "sred = subaru_reduction(filter_name, rootdir)\n",
    "\n",
    "dirs = obs_dirs(rootdir, filter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    shutil.rmtree(dirs['coord_maps'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "coord_maps = [p for p in os.listdir(coord_maps_dir) if p.endswith('.coo')]\n",
    "os.mkdir(dirs['coord_maps'])\n",
    "for p in coord_maps:\n",
    "    src = os.path.join(coord_maps_dir, p)\n",
    "    dst = os.path.join(dirs['coord_maps'], p)\n",
    "    shutil.copy(src,dst)\n",
    "\n",
    "detectors = ['chihiro', 'clarisse', 'fio', 'kiki', 'nausicaa', 'ponyo', 'san', 'satsuki', 'sheeta', 'sophie']\n",
    "\n",
    "for d in detectors:\n",
    "    res, res_df = sred.map_detector(d, degree=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Bias and Overscan Regions\n",
    "\n",
    "This takes 2 minutes. The de-biased images are in the directory `<rootdir>/<filter_name>/no_bias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.no_bias import remove_oscan\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(dirs['no_bias'])\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(dirs['no_bias'])\n",
    "\n",
    "image_filter = {'DATA-TYP':'OBJECT', 'FILTER01': filter_name}\n",
    "im_files = raw_fits.files_filtered(include_path=True, **image_filter)\n",
    "\n",
    "for imf in im_files:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        #need the real header, apparently CCDData.read doesn't return WCS in header\n",
    "        with fits.open(imf) as hdul:\n",
    "            hdr = hdul[0].header.copy()\n",
    "            data = hdul[0].data.astype(np.float32)\n",
    "\n",
    "        detector = hdr['DETECTOR']\n",
    "        print(f'file: {os.path.basename(imf)}, detector: {detector}')\n",
    "\n",
    "        if combined_bias_dir is not None:\n",
    "            bias_path = os.path.join(combined_bias_dir, detector+ '.fits')\n",
    "            with fits.open(bias_path) as f:\n",
    "                bias = f[0].data.copy()\n",
    "        else:\n",
    "            bias = None\n",
    "\n",
    "        new_hdr, no_oscan = remove_oscan(hdr, data, bias)\n",
    "\n",
    "        phdu = fits.PrimaryHDU(data = no_oscan, header=new_hdr)\n",
    "        outfile = os.path.join(dirs['no_bias'], os.path.basename(imf))\n",
    "        phdu.writeto(outfile, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Images\n",
    "\n",
    "This takes about 3 minutes unless `remove_cosmic_rays = True` in which case it takes about 15 minutes. The results are in the directory `<rootdir>/<filter_name>/registered_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccdproc import ImageFileCollection\n",
    "try:\n",
    "    shutil.rmtree(dirs['registered_image'])\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(dirs['registered_image'])\n",
    "\n",
    "imgs = ImageFileCollection(dirs['no_bias'])\n",
    "\n",
    "for img in imgs.files:\n",
    "    print(f'Tranforming: {img}')\n",
    "    res=sred.transform_image(os.path.splitext(img)[0], remove_cosmic_rays = remove_cosmic_rays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Individual Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sub-process takes about 12 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MontagePy.main import mImgtbl\n",
    "\n",
    "imgdir = dirs['registered_image']\n",
    "raw_image_tbl = os.path.join(image_dir, 'raw_image.tbl')\n",
    "\n",
    "rtn = mImgtbl(imgdir, raw_image_tbl)\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MontagePy.main import mMakeHdr, mProjExec, mAdd\n",
    "hdrfile = os.path.join(image_dir, 'mosaic.hdr')\n",
    "rtn = mMakeHdr(raw_image_tbl, hdrfile )\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree(dirs['projected_image'])\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(dirs['projected_image'])\n",
    "projdir = dirs['projected_image']\n",
    "rtn = mProjExec(imgdir, raw_image_tbl, hdrfile, projdir=projdir, quickMode=True)\n",
    "rtn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Final Mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes about one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projdir = dirs['projected_image']\n",
    "pimage_tbl = os.path.join(image_dir, 'pimages.tbl')\n",
    "\n",
    "rtn = mImgtbl(projdir, pimage_tbl )\n",
    "print(f'mImgtbl returned: {rtn}')\n",
    "\n",
    "#coadd into a temp file\n",
    "tmp_out = os.path.join(image_dir, 'tmp_mosaic.fits')\n",
    "\n",
    "rtn = mAdd(projdir, pimage_tbl,  hdrfile, tmp_out, coadd=1)\n",
    "print(f'mAdd returned: {rtn}')\n",
    "\n",
    "# convert to single precision\n",
    "mosaic_fits = os.path.join(rootdir,  fits_out)\n",
    "with fits.open(tmp_out) as f:\n",
    "    img_hdr=f[0].header.copy()\n",
    "    img_data = f[0].data.astype(np.float32)\n",
    "\n",
    "# tack on the comments to the header\n",
    "img_hdr['COMMENT'] = '----------- Observation Comments -----------------'\n",
    "for c in comments:\n",
    "    img_hdr['COMMENT'] = c\n",
    "\n",
    "phdu = fits.PrimaryHDU(data = img_data, header = img_hdr)\n",
    "phdu.writeto(mosaic_fits, overwrite=True)\n",
    "\n",
    "try:\n",
    "    os.remove(tmp_out)\n",
    "    os.remove(os.path.join(rootdir, filter_name, 'tmp_mosaic_area.fits'))\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyraf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
