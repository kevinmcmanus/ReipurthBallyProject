{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subaru Data Reduction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Reduction Parameters\n",
    "\n",
    "In the box below, you specify various parameters of the reduction process. These include the root directory of the reduction process. Included here is the directory that contains all of the fits files to be used in the reduction.\n",
    "\n",
    "The process includes only fits files produced using a specified filter. This filter is specified by the variable `filter_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observation parameters\n",
    "\n",
    "clean = False # if true, remove all directories and start afresh\n",
    "\n",
    "filter_name = 'N-A-L671' #process all files for this filter\n",
    "rootdir = '/home/kevin/Documents/Pelican'\n",
    "raw_fits_dir = 'all_fits' # where all the raw fits files live\n",
    "\n",
    "fits_out = 'Pelican_sii.fits' #name of the resulting image which will go rootdir\n",
    "\n",
    "combined_bias_dir = '/home/kevin/Documents/M8data/M8/combined_bias' # set to None if no bias files\n",
    "\n",
    "repo_dir = '/home/kevin/repos/ReipurthBallyProject' #directory where the repo was cloned\n",
    "\n",
    "remove_cosmic_rays = False #True invokes ccdproc.cosmicray_lacosmic (adds 10 minutes to processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static data\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "coord_maps_dir = os.path.join(repo_dir,'SubaruCoordinateMaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyraf import iraf\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from ccdproc import ImageFileCollection\n",
    "from src.pyrafutils import  subaru_reduction, obs_dirs\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = ['FRAMEID', 'EXP-ID', 'DATA-TYP', 'EXPTIME', 'FILTER01', 'DETECTOR']\n",
    "raw_fits = ImageFileCollection(os.path.join(rootdir, raw_fits_dir), keywords=kw)\n",
    "\n",
    "#did we get valid filter?\n",
    "filters = raw_fits.values('FILTER01', unique=True)\n",
    "if filter_name not in filters:\n",
    "    print(f'Invalid filter name: {filter_name}')\n",
    "    print(f'valid filters names are: {filters}')\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Coordinate Transformation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.path.join(rootdir, filter_name)\n",
    "#zap the image directory if needed\n",
    "if clean:\n",
    "    #blow it all away\n",
    "    try:\n",
    "        shutil.rmtree(image_dir)\n",
    "    except:\n",
    "        pass\n",
    "if not os.path.exists(image_dir):\n",
    "    os.mkdir(image_dir)\n",
    "\n",
    "os.chdir(image_dir)\n",
    "sred = subaru_reduction(filter_name, rootdir)\n",
    "\n",
    "dirs = obs_dirs(rootdir, filter_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    shutil.rmtree(dirs['coord_maps'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "coord_maps = [p for p in os.listdir(coord_maps_dir) if p.endswith('.coo')]\n",
    "os.mkdir(dirs['coord_maps'])\n",
    "for p in coord_maps:\n",
    "    src = os.path.join(coord_maps_dir, p)\n",
    "    dst = os.path.join(dirs['coord_maps'], p)\n",
    "    shutil.copy(src,dst)\n",
    "\n",
    "detectors = ['chihiro', 'clarisse', 'fio', 'kiki', 'nausicaa', 'ponyo', 'san', 'satsuki', 'sheeta', 'sophie']\n",
    "\n",
    "for d in detectors:\n",
    "    res, res_df = sred.map_detector(d, degree=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Bias and Overscan Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: SUPA01469800.fits, detector: nausicaa\n",
      "file: SUPA01469801.fits, detector: kiki\n",
      "file: SUPA01469802.fits, detector: fio\n",
      "file: SUPA01469803.fits, detector: sophie\n",
      "file: SUPA01469804.fits, detector: sheeta\n",
      "file: SUPA01469805.fits, detector: satsuki\n",
      "file: SUPA01469806.fits, detector: chihiro\n",
      "file: SUPA01469807.fits, detector: clarisse\n",
      "file: SUPA01469808.fits, detector: ponyo\n",
      "file: SUPA01469809.fits, detector: san\n",
      "file: SUPA01469810.fits, detector: nausicaa\n",
      "file: SUPA01469811.fits, detector: kiki\n",
      "file: SUPA01469812.fits, detector: fio\n",
      "file: SUPA01469813.fits, detector: sophie\n",
      "file: SUPA01469814.fits, detector: sheeta\n",
      "file: SUPA01469815.fits, detector: satsuki\n",
      "file: SUPA01469816.fits, detector: chihiro\n",
      "file: SUPA01469817.fits, detector: clarisse\n",
      "file: SUPA01469818.fits, detector: ponyo\n",
      "file: SUPA01469819.fits, detector: san\n",
      "file: SUPA01469820.fits, detector: nausicaa\n",
      "file: SUPA01469821.fits, detector: kiki\n",
      "file: SUPA01469822.fits, detector: fio\n",
      "file: SUPA01469823.fits, detector: sophie\n",
      "file: SUPA01469824.fits, detector: sheeta\n",
      "file: SUPA01469825.fits, detector: satsuki\n",
      "file: SUPA01469826.fits, detector: chihiro\n",
      "file: SUPA01469827.fits, detector: clarisse\n",
      "file: SUPA01469828.fits, detector: ponyo\n",
      "file: SUPA01469829.fits, detector: san\n",
      "file: SUPA01469830.fits, detector: nausicaa\n",
      "file: SUPA01469831.fits, detector: kiki\n",
      "file: SUPA01469832.fits, detector: fio\n",
      "file: SUPA01469833.fits, detector: sophie\n",
      "file: SUPA01469834.fits, detector: sheeta\n",
      "file: SUPA01469835.fits, detector: satsuki\n",
      "file: SUPA01469836.fits, detector: chihiro\n",
      "file: SUPA01469837.fits, detector: clarisse\n",
      "file: SUPA01469838.fits, detector: ponyo\n",
      "file: SUPA01469839.fits, detector: san\n",
      "file: SUPA01469840.fits, detector: nausicaa\n",
      "file: SUPA01469841.fits, detector: kiki\n",
      "file: SUPA01469842.fits, detector: fio\n",
      "file: SUPA01469843.fits, detector: sophie\n",
      "file: SUPA01469844.fits, detector: sheeta\n",
      "file: SUPA01469845.fits, detector: satsuki\n",
      "file: SUPA01469846.fits, detector: chihiro\n",
      "file: SUPA01469847.fits, detector: clarisse\n",
      "file: SUPA01469848.fits, detector: ponyo\n",
      "file: SUPA01469849.fits, detector: san\n"
     ]
    }
   ],
   "source": [
    "from src.no_bias import remove_oscan\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(dirs['no_bias'])\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(dirs['no_bias'])\n",
    "\n",
    "image_filter = {'DATA-TYP':'OBJECT', 'FILTER01': filter_name}\n",
    "im_files = raw_fits.files_filtered(include_path=True, **image_filter)\n",
    "\n",
    "for imf in im_files:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "\n",
    "        #need the real header, apparently CCDData.read doesn't return WCS in header\n",
    "        with fits.open(imf) as hdul:\n",
    "            hdr = hdul[0].header.copy()\n",
    "            data = hdul[0].data.astype(np.float32)\n",
    "\n",
    "        detector = hdr['DETECTOR']\n",
    "        print(f'file: {os.path.basename(imf)}, detector: {detector}')\n",
    "\n",
    "        if combined_bias_dir is not None:\n",
    "            bias_path = os.path.join(combined_bias_dir, detector+ '.fits')\n",
    "            with fits.open(bias_path) as f:\n",
    "                bias = f[0].data.copy()\n",
    "        else:\n",
    "            bias = None\n",
    "\n",
    "        new_hdr, no_oscan = remove_oscan(hdr, data, bias)\n",
    "\n",
    "        phdu = fits.PrimaryHDU(data = no_oscan, header=new_hdr)\n",
    "        outfile = os.path.join(dirs['no_bias'], os.path.basename(imf))\n",
    "        phdu.writeto(outfile, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tranforming: SUPA01469800.fits\n",
      "Tranforming: SUPA01469801.fits\n",
      "Tranforming: SUPA01469802.fits\n",
      "Tranforming: SUPA01469803.fits\n",
      "Tranforming: SUPA01469804.fits\n",
      "Tranforming: SUPA01469805.fits\n",
      "Tranforming: SUPA01469806.fits\n",
      "Tranforming: SUPA01469807.fits\n",
      "Tranforming: SUPA01469808.fits\n",
      "Tranforming: SUPA01469809.fits\n",
      "Tranforming: SUPA01469810.fits\n",
      "Tranforming: SUPA01469811.fits\n",
      "Tranforming: SUPA01469812.fits\n",
      "Tranforming: SUPA01469813.fits\n",
      "Tranforming: SUPA01469814.fits\n",
      "Tranforming: SUPA01469815.fits\n",
      "Tranforming: SUPA01469816.fits\n",
      "Tranforming: SUPA01469817.fits\n",
      "Tranforming: SUPA01469818.fits\n",
      "Tranforming: SUPA01469819.fits\n",
      "Tranforming: SUPA01469820.fits\n",
      "Tranforming: SUPA01469821.fits\n",
      "Tranforming: SUPA01469822.fits\n",
      "Tranforming: SUPA01469823.fits\n",
      "Tranforming: SUPA01469824.fits\n",
      "Tranforming: SUPA01469825.fits\n",
      "Tranforming: SUPA01469826.fits\n",
      "Tranforming: SUPA01469827.fits\n",
      "Tranforming: SUPA01469828.fits\n",
      "Tranforming: SUPA01469829.fits\n",
      "Tranforming: SUPA01469830.fits\n",
      "Tranforming: SUPA01469831.fits\n",
      "Tranforming: SUPA01469832.fits\n",
      "Tranforming: SUPA01469833.fits\n",
      "Tranforming: SUPA01469834.fits\n",
      "Tranforming: SUPA01469835.fits\n",
      "Tranforming: SUPA01469836.fits\n",
      "Tranforming: SUPA01469837.fits\n",
      "Tranforming: SUPA01469838.fits\n",
      "Tranforming: SUPA01469839.fits\n",
      "Tranforming: SUPA01469840.fits\n",
      "Tranforming: SUPA01469841.fits\n",
      "Tranforming: SUPA01469842.fits\n",
      "Tranforming: SUPA01469843.fits\n",
      "Tranforming: SUPA01469844.fits\n",
      "Tranforming: SUPA01469845.fits\n",
      "Tranforming: SUPA01469846.fits\n",
      "Tranforming: SUPA01469847.fits\n",
      "Tranforming: SUPA01469848.fits\n",
      "Tranforming: SUPA01469849.fits\n"
     ]
    }
   ],
   "source": [
    "from ccdproc import ImageFileCollection\n",
    "try:\n",
    "    shutil.rmtree(dirs['registered_image'])\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(dirs['registered_image'])\n",
    "\n",
    "imgs = ImageFileCollection(dirs['no_bias'])\n",
    "\n",
    "for img in imgs.files:\n",
    "    print(f'Tranforming: {img}')\n",
    "    res=sred.transform_image(os.path.splitext(img)[0], remove_cosmic_rays = remove_cosmic_rays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Individual Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sub-process takes about 12 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': '0', 'count': 50, 'badfits': 0, 'badwcs': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MontagePy.main import mImgtbl\n",
    "\n",
    "imgdir = dirs['registered_image']\n",
    "raw_image_tbl = os.path.join(image_dir, 'raw_image.tbl')\n",
    "\n",
    "rtn = mImgtbl(imgdir, raw_image_tbl)\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': '0',\n",
       " 'count': 50,\n",
       " 'ncube': 0,\n",
       " 'naxis1': 11275,\n",
       " 'naxis2': 9228,\n",
       " 'clon': 312.68929162276174,\n",
       " 'clat': 44.352934494522735,\n",
       " 'lonsize': 0.63264025,\n",
       " 'latsize': 0.5177830800000001,\n",
       " 'posang': 359.9765342250354,\n",
       " 'lon1': 313.12956525873705,\n",
       " 'lat1': 44.09306981547718,\n",
       " 'lon2': 312.24872080175743,\n",
       " 'lat2': 44.09332776928199,\n",
       " 'lon3': 312.2451090258769,\n",
       " 'lat3': 44.61109299405244,\n",
       " 'lon4': 313.13377011381607,\n",
       " 'lat4': 44.61083275120581}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MontagePy.main import mMakeHdr, mProjExec, mAdd\n",
    "hdrfile = os.path.join(image_dir, 'mosaic.hdr')\n",
    "rtn = mMakeHdr(raw_image_tbl, hdrfile )\n",
    "rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': '0', 'count': 50, 'failed': 0, 'nooverlap': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(dirs['projected_image'])\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(dirs['projected_image'])\n",
    "projdir = dirs['projected_image']\n",
    "rtn = mProjExec(imgdir, raw_image_tbl, hdrfile, projdir=projdir, quickMode=True)\n",
    "rtn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Final Mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes about one minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mImgtbl returned: {'status': '0', 'count': 50, 'badfits': 0, 'badwcs': 0}\n",
      "mAdd returned: {'status': '0', 'time': 47.0}\n"
     ]
    }
   ],
   "source": [
    "projdir = dirs['projected_image']\n",
    "pimage_tbl = os.path.join(image_dir, 'pimages.tbl')\n",
    "\n",
    "rtn = mImgtbl(projdir, pimage_tbl )\n",
    "print(f'mImgtbl returned: {rtn}')\n",
    "\n",
    "#coadd into a temp file\n",
    "tmp_out = os.path.join(image_dir, 'tmp_mosaic.fits')\n",
    "\n",
    "rtn = mAdd(projdir, pimage_tbl,  hdrfile, tmp_out, coadd=1)\n",
    "print(f'mAdd returned: {rtn}')\n",
    "\n",
    "# convert to single precision\n",
    "mosaic_fits = os.path.join(rootdir,  fits_out)\n",
    "with fits.open(tmp_out) as f:\n",
    "    img_hdr=f[0].header\n",
    "    img_data = f[0].data.astype(np.float32)\n",
    "phdu = fits.PrimaryHDU(data = img_data, header = img_hdr)\n",
    "phdu.writeto(mosaic_fits, overwrite=True)\n",
    "\n",
    "try:\n",
    "    os.remove(tmp_out)\n",
    "    os.remove(os.path.join(rootdir, filter_name, 'tmp_mosaic_area.fits'))\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyraf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
